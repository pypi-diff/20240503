# Comparing `tmp/ppacls-0.4.3-py3-none-any.whl.zip` & `tmp/ppacls-0.4.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,32 +1,32 @@
-Zip file size: 56223 bytes, number of entries: 30
--rw-rw-rw-  2.0 fat      196 b- defN 24-Apr-27 06:41 ppacls/__init__.py
--rw-rw-rw-  2.0 fat     9423 b- defN 23-Aug-30 14:35 ppacls/predict.py
--rw-rw-rw-  2.0 fat    27319 b- defN 24-Apr-27 06:41 ppacls/trainer.py
+Zip file size: 57134 bytes, number of entries: 30
+-rw-rw-rw-  2.0 fat      196 b- defN 24-May-03 03:45 ppacls/__init__.py
+-rw-rw-rw-  2.0 fat     8988 b- defN 24-May-02 05:00 ppacls/predict.py
+-rw-rw-rw-  2.0 fat    28974 b- defN 24-May-02 05:49 ppacls/trainer.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Nov-04 14:44 ppacls/data_utils/__init__.py
 -rw-rw-rw-  2.0 fat    22219 b- defN 24-Apr-27 05:31 ppacls/data_utils/audio.py
--rw-rw-rw-  2.0 fat      909 b- defN 23-Feb-15 13:35 ppacls/data_utils/collate_fn.py
--rw-rw-rw-  2.0 fat     3771 b- defN 23-Aug-07 14:51 ppacls/data_utils/featurizer.py
--rw-rw-rw-  2.0 fat     5507 b- defN 23-Sep-13 12:00 ppacls/data_utils/reader.py
+-rw-rw-rw-  2.0 fat      947 b- defN 24-May-02 05:13 ppacls/data_utils/collate_fn.py
+-rw-rw-rw-  2.0 fat     3919 b- defN 24-May-02 04:53 ppacls/data_utils/featurizer.py
+-rw-rw-rw-  2.0 fat     7042 b- defN 24-May-02 09:38 ppacls/data_utils/reader.py
 -rw-rw-rw-  2.0 fat     1581 b- defN 23-Aug-07 14:51 ppacls/data_utils/spec_aug.py
 -rw-rw-rw-  2.0 fat     4698 b- defN 24-Jan-28 04:01 ppacls/data_utils/utils.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Nov-05 11:08 ppacls/models/__init__.py
 -rw-rw-rw-  2.0 fat    12884 b- defN 23-Aug-09 10:07 ppacls/models/campplus.py
--rw-rw-rw-  2.0 fat    11182 b- defN 23-Aug-09 09:51 ppacls/models/ecapa_tdnn.py
+-rw-rw-rw-  2.0 fat    11092 b- defN 24-May-02 04:42 ppacls/models/ecapa_tdnn.py
 -rw-rw-rw-  2.0 fat    10451 b- defN 23-Aug-10 10:24 ppacls/models/eres2net.py
 -rw-rw-rw-  2.0 fat     9863 b- defN 23-Aug-07 14:51 ppacls/models/panns.py
 -rw-rw-rw-  2.0 fat     5277 b- defN 23-Aug-10 10:24 ppacls/models/pooling.py
 -rw-rw-rw-  2.0 fat     6941 b- defN 23-Aug-09 09:51 ppacls/models/res2net.py
 -rw-rw-rw-  2.0 fat     5760 b- defN 23-Aug-09 09:51 ppacls/models/resnet_se.py
 -rw-rw-rw-  2.0 fat     3557 b- defN 23-Aug-09 09:51 ppacls/models/tdnn.py
 -rw-rw-rw-  2.0 fat     5049 b- defN 23-Mar-18 10:41 ppacls/models/utils.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Nov-04 14:44 ppacls/utils/__init__.py
 -rw-rw-rw-  2.0 fat     2839 b- defN 22-Nov-04 14:44 ppacls/utils/logger.py
 -rw-rw-rw-  2.0 fat     1067 b- defN 23-Mar-23 11:45 ppacls/utils/record.py
 -rw-rw-rw-  2.0 fat     3399 b- defN 23-Aug-05 12:19 ppacls/utils/scheduler.py
 -rw-rw-rw-  2.0 fat     4301 b- defN 24-Apr-27 04:49 ppacls/utils/utils.py
--rw-rw-rw-  2.0 fat    11558 b- defN 24-Apr-27 06:42 ppacls-0.4.3.dist-info/LICENSE
--rw-rw-rw-  2.0 fat    22776 b- defN 24-Apr-27 06:42 ppacls-0.4.3.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 24-Apr-27 06:42 ppacls-0.4.3.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        7 b- defN 24-Apr-27 06:42 ppacls-0.4.3.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     2407 b- defN 24-Apr-27 06:42 ppacls-0.4.3.dist-info/RECORD
-30 files, 195033 bytes uncompressed, 52401 bytes compressed:  73.1%
+-rw-rw-rw-  2.0 fat    11558 b- defN 24-May-03 03:45 ppacls-0.4.4.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat    23734 b- defN 24-May-03 03:45 ppacls-0.4.4.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 24-May-03 03:45 ppacls-0.4.4.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        7 b- defN 24-May-03 03:45 ppacls-0.4.4.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     2407 b- defN 24-May-03 03:45 ppacls-0.4.4.dist-info/RECORD
+30 files, 198842 bytes uncompressed, 53312 bytes compressed:  73.2%
```

## zipnote {}

```diff
@@ -69,23 +69,23 @@
 
 Filename: ppacls/utils/scheduler.py
 Comment: 
 
 Filename: ppacls/utils/utils.py
 Comment: 
 
-Filename: ppacls-0.4.3.dist-info/LICENSE
+Filename: ppacls-0.4.4.dist-info/LICENSE
 Comment: 
 
-Filename: ppacls-0.4.3.dist-info/METADATA
+Filename: ppacls-0.4.4.dist-info/METADATA
 Comment: 
 
-Filename: ppacls-0.4.3.dist-info/WHEEL
+Filename: ppacls-0.4.4.dist-info/WHEEL
 Comment: 
 
-Filename: ppacls-0.4.3.dist-info/top_level.txt
+Filename: ppacls-0.4.4.dist-info/top_level.txt
 Comment: 
 
-Filename: ppacls-0.4.3.dist-info/RECORD
+Filename: ppacls-0.4.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## ppacls/__init__.py

```diff
@@ -1,4 +1,4 @@
-__version__ = "0.4.3"
+__version__ = "0.4.4"
 # 项目支持的模型
 SUPPORT_MODEL = ['EcapaTdnn', 'PANNS_CNN6', 'PANNS_CNN10', 'PANNS_CNN14', 'Res2Net', 'ResNetSE', 'TDNN', 'ERes2Net',
                  'CAMPPlus']
```

## ppacls/predict.py

```diff
@@ -43,15 +43,15 @@
             with open(configs, 'r', encoding='utf-8') as f:
                 configs = yaml.load(f.read(), Loader=yaml.FullLoader)
             print_arguments(configs=configs)
         self.configs = dict_to_object(configs)
         assert self.configs.use_model in SUPPORT_MODEL, f'没有该模型：{self.configs.use_model}'
         # 获取特征提取器
         self._audio_featurizer = AudioFeaturizer(feature_method=self.configs.preprocess_conf.feature_method,
-                                                method_args=self.configs.preprocess_conf.get('method_args', {}))
+                                                 method_args=self.configs.preprocess_conf.get('method_args', {}))
         # 获取分类标签
         with open(self.configs.dataset_conf.label_list_path, 'r', encoding='utf-8') as f:
             lines = f.readlines()
         self.class_labels = [l.replace('\n', '') for l in lines]
         # 自动获取列表数量
         if self.configs.model_conf.num_class is None:
             self.configs.model_conf.num_class = len(self.class_labels)
@@ -120,21 +120,17 @@
         :param audio_data: 需要识别的数据，支持文件路径，文件对象，字节，numpy。如果是字节的话，必须是完整并带格式的字节文件
         :param sample_rate: 如果传入的事numpy数据，需要指定采样率
         :return: 结果标签和对应的得分
         """
         # 加载音频文件，并进行预处理
         input_data = self._load_audio(audio_data=audio_data, sample_rate=sample_rate)
         input_data = paddle.to_tensor(input_data.samples, dtype=paddle.float32).unsqueeze(0)
-        input_len_ratio = paddle.to_tensor([1], dtype=paddle.float32)
-        audio_feature, _ = self._audio_featurizer(input_data, input_len_ratio)
+        audio_feature = self._audio_featurizer(input_data)
         # 执行预测
-        if self.configs.use_model == 'EcapaTdnn':
-            output = self.predictor([audio_feature, input_len_ratio])
-        else:
-            output = self.predictor(audio_feature)
+        output = self.predictor(audio_feature)
         result = paddle.nn.functional.softmax(output).numpy()[0]
         # 最大概率的label
         lab = np.argsort(result)[-1]
         score = result[lab]
         return self.class_labels[lab], round(float(score), 5)
 
     def predict_batch(self, audios_data, sample_rate=16000):
@@ -151,31 +147,27 @@
             audios_data1.append(input_data.samples)
             data_length.append(input_data.num_samples)
         # 找出音频长度最长的
         batch = sorted(audios_data1, key=lambda a: a.shape[0], reverse=True)
         max_audio_length = batch[0].shape[0]
         batch_size = len(batch)
         # 以最大的长度创建0张量
-        inputs = np.zeros((batch_size, max_audio_length), dtype='float32')
+        inputs = np.zeros((batch_size, max_audio_length), dtype=np.float32)
         input_lens_ratio = []
         for x in range(batch_size):
             tensor = audios_data1[x]
             seq_length = tensor.shape[0]
             # 将数据插入都0张量中，实现了padding
             inputs[x, :seq_length] = tensor[:]
             input_lens_ratio.append(seq_length / max_audio_length)
-        input_lens_ratio = paddle.to_tensor(input_lens_ratio, dtype=paddle.float32)
         inputs = paddle.to_tensor(inputs, dtype=paddle.float32)
-        audio_feature = self._audio_featurizer(inputs)
-        data_length = paddle.to_tensor([audio_feature.shape[1]], dtype=paddle.int64)
+        input_lens_ratio = paddle.to_tensor(input_lens_ratio, dtype=paddle.float32)
+        audio_feature = self._audio_featurizer(inputs, input_lens_ratio)
         # 执行预测
-        if self.configs.use_model == 'EcapaTdnn':
-            output = self.predictor([audio_feature, data_length])
-        else:
-            output = self.predictor(audio_feature)
+        output = self.predictor(audio_feature)
         results = paddle.nn.functional.softmax(output).numpy()
         labels, scores = [], []
         for result in results:
             lab = np.argsort(result)[-1]
             score = result[lab]
             labels.append(self.class_labels[lab])
             scores.append(round(float(score), 5))
```

## ppacls/trainer.py

```diff
@@ -1,29 +1,30 @@
 import json
 import os
 import platform
 import shutil
 import time
 from datetime import timedelta
 
+import numpy as np
 import paddle
 import yaml
 from paddle import summary
 from paddle.distributed import fleet
 from paddle.io import DataLoader, DistributedBatchSampler
 from paddle.metric import accuracy
 from paddle.optimizer.lr import CosineAnnealingDecay
 from sklearn.metrics import confusion_matrix
 from tqdm import tqdm
 from visualdl import LogWriter
 
 from ppacls import SUPPORT_MODEL, __version__
 from ppacls.data_utils.collate_fn import collate_fn
 from ppacls.data_utils.featurizer import AudioFeaturizer
-from ppacls.data_utils.reader import CustomDataset
+from ppacls.data_utils.reader import PPAClsDataset
 from ppacls.data_utils.spec_aug import SpecAug
 from ppacls.models.campplus import CAMPPlus
 from ppacls.models.ecapa_tdnn import EcapaTdnn
 from ppacls.models.eres2net import ERes2Net
 from ppacls.models.panns import PANNS_CNN6, PANNS_CNN10, PANNS_CNN14
 from ppacls.models.res2net import Res2Net
 from ppacls.models.resnet_se import ResNetSE
@@ -53,37 +54,42 @@
         if isinstance(configs, str):
             with open(configs, 'r', encoding='utf-8') as f:
                 configs = yaml.load(f.read(), Loader=yaml.FullLoader)
             print_arguments(configs=configs)
         self.configs = dict_to_object(configs)
         assert self.configs.use_model in SUPPORT_MODEL, f'没有该模型：{self.configs.use_model}'
         self.model = None
+        self.audio_featurizer = None
+        self.train_dataset = None
+        self.train_loader = None
+        self.test_dataset = None
         self.test_loader = None
         self.amp_scaler = None
         # 获取分类标签
         with open(self.configs.dataset_conf.label_list_path, 'r', encoding='utf-8') as f:
             lines = f.readlines()
         self.class_labels = [l.replace('\n', '') for l in lines]
-        # 获取特征器
-        self.audio_featurizer = AudioFeaturizer(feature_method=self.configs.preprocess_conf.feature_method,
-                                                method_args=self.configs.preprocess_conf.get('method_args', {}))
         self.spec_aug = SpecAug(**self.configs.dataset_conf.get('spec_aug_args', {}))
         if platform.system().lower() == 'windows':
             self.configs.dataset_conf.dataLoader.num_workers = 0
             logger.warning('Windows系统不支持多线程读取数据，已自动关闭！')
         self.max_step, self.train_step = None, None
         self.train_loss, self.train_acc = None, None
         self.train_eta_sec = None
         self.eval_loss, self.eval_acc = None, None
         self.test_log_step, self.train_log_step = 0, 0
         self.stop_train, self.stop_eval = False, False
 
     def __setup_dataloader(self, is_train=False):
+        # 获取特征器
+        self.audio_featurizer = AudioFeaturizer(feature_method=self.configs.preprocess_conf.feature_method,
+                                                method_args=self.configs.preprocess_conf.get('method_args', {}))
         if is_train:
-            self.train_dataset = CustomDataset(data_list_path=self.configs.dataset_conf.train_list,
+            self.train_dataset = PPAClsDataset(data_list_path=self.configs.dataset_conf.train_list,
+                                               audio_featurizer=self.audio_featurizer,
                                                do_vad=self.configs.dataset_conf.do_vad,
                                                max_duration=self.configs.dataset_conf.max_duration,
                                                min_duration=self.configs.dataset_conf.min_duration,
                                                aug_conf=self.configs.dataset_conf.aug_conf,
                                                sample_rate=self.configs.dataset_conf.sample_rate,
                                                use_dB_normalization=self.configs.dataset_conf.use_dB_normalization,
                                                target_dB=self.configs.dataset_conf.target_dB,
@@ -97,28 +103,54 @@
                                                         shuffle=True)
             self.train_loader = DataLoader(dataset=self.train_dataset,
                                            collate_fn=collate_fn,
                                            shuffle=(train_sampler is None),
                                            batch_sampler=train_sampler,
                                            **self.configs.dataset_conf.dataLoader)
         # 获取测试数据
-        self.test_dataset = CustomDataset(data_list_path=self.configs.dataset_conf.test_list,
+        self.test_dataset = PPAClsDataset(data_list_path=self.configs.dataset_conf.test_list,
+                                          audio_featurizer=self.audio_featurizer,
                                           do_vad=self.configs.dataset_conf.do_vad,
                                           max_duration=self.configs.dataset_conf.eval_conf.max_duration,
                                           min_duration=self.configs.dataset_conf.min_duration,
                                           sample_rate=self.configs.dataset_conf.sample_rate,
                                           use_dB_normalization=self.configs.dataset_conf.use_dB_normalization,
                                           target_dB=self.configs.dataset_conf.target_dB,
                                           mode='eval')
         self.test_loader = DataLoader(dataset=self.test_dataset,
                                       collate_fn=collate_fn,
                                       shuffle=True,
                                       batch_size=self.configs.dataset_conf.eval_conf.batch_size,
                                       num_workers=self.configs.dataset_conf.dataLoader.num_workers)
 
+    # 提取特征保存文件
+    def extract_features(self, save_dir='dataset/features'):
+        self.audio_featurizer = AudioFeaturizer(feature_method=self.configs.preprocess_conf.feature_method,
+                                                method_args=self.configs.preprocess_conf.get('method_args', {}))
+        for i, data_list in enumerate([self.configs.dataset_conf.train_list, self.configs.dataset_conf.test_list]):
+            # 获取测试数据
+            test_dataset = PPAClsDataset(data_list_path=data_list,
+                                         audio_featurizer=self.audio_featurizer,
+                                         do_vad=self.configs.dataset_conf.do_vad,
+                                         sample_rate=self.configs.dataset_conf.sample_rate,
+                                         use_dB_normalization=self.configs.dataset_conf.use_dB_normalization,
+                                         target_dB=self.configs.dataset_conf.target_dB,
+                                         mode='extract_feature')
+            save_data_list = data_list.replace('.txt', '_features.txt')
+            with open(save_data_list, 'w', encoding='utf-8') as f:
+                for i in tqdm(range(len(test_dataset))):
+                    feature, label = test_dataset[i]
+                    feature = feature.numpy()
+                    label = int(label)
+                    save_path = os.path.join(save_dir, str(label), f'{int(time.time() * 1000)}.npy').replace('\\', '/')
+                    os.makedirs(os.path.dirname(save_path), exist_ok=True)
+                    np.save(save_path, feature)
+                    f.write(f'{save_path}\t{label}\n')
+            logger.info(f'{data_list}列表中的数据已提取特征完成，新列表为：{save_data_list}')
+
     def __setup_model(self, input_size, is_train=False):
         # 自动获取列表数量
         if self.configs.model_conf.num_class is None:
             self.configs.model_conf.num_class = len(self.class_labels)
         # 获取模型
         if self.configs.use_model == 'EcapaTdnn':
             self.model = EcapaTdnn(input_size=input_size, **self.configs.model_conf)
@@ -136,15 +168,15 @@
             self.model = TDNN(input_size=input_size, **self.configs.model_conf)
         elif self.configs.use_model == 'ERes2Net':
             self.model = ERes2Net(input_size=input_size, **self.configs.model_conf)
         elif self.configs.use_model == 'CAMPPlus':
             self.model = CAMPPlus(input_size=input_size, **self.configs.model_conf)
         else:
             raise Exception(f'{self.configs.use_model} 模型不存在！')
-        summary(self.model, (1, 98, self.audio_featurizer.feature_dim))
+        summary(self.model, (1, 98, input_size))
         # print(self.model)
         # 获取损失函数
         weight = paddle.to_tensor(self.configs.train_conf.loss_weight, dtype=paddle.float32) \
             if self.configs.train_conf.loss_weight is not None else None
         self.loss = paddle.nn.CrossEntropyLoss(weight=weight)
         if is_train:
             if self.configs.train_conf.enable_amp:
@@ -260,26 +292,22 @@
             if os.path.exists(old_model_path):
                 shutil.rmtree(old_model_path)
         logger.info('已保存模型：{}'.format(model_path))
 
     def __train_epoch(self, epoch_id, local_rank, writer):
         train_times, accuracies, loss_sum = [], [], []
         start = time.time()
-        for batch_id, (audio, label, input_lens_ratio) in enumerate(self.train_loader()):
+        for batch_id, (features, label, input_lens) in enumerate(self.train_loader()):
             if self.stop_train: break
-            features, _ = self.audio_featurizer(audio, input_lens_ratio)
             # 特征增强
             if self.configs.dataset_conf.use_spec_aug:
                 features = self.spec_aug(features)
             # 执行模型计算，是否开启自动混合精度
             with paddle.amp.auto_cast(enable=self.configs.train_conf.enable_amp, level='O1'):
-                if self.configs.use_model == 'EcapaTdnn':
-                    output = self.model([features, input_lens_ratio])
-                else:
-                    output = self.model(features)
+                output = self.model(features)
             # 计算损失值
             los = self.loss(output, label)
             # 是否开启自动混合精度
             if self.configs.train_conf.enable_amp:
                 # loss缩放，乘以系数loss_scaling
                 scaled = self.amp_scaler.scale(los)
                 scaled.backward()
@@ -423,21 +451,17 @@
         if isinstance(self.model, paddle.DataParallel):
             eval_model = self.model._layers
         else:
             eval_model = self.model
 
         accuracies, losses, preds, labels = [], [], [], []
         with paddle.no_grad():
-            for batch_id, (audio, label, input_lens_ratio) in enumerate(tqdm(self.test_loader())):
+            for batch_id, (features, label, input_lens) in enumerate(tqdm(self.test_loader())):
                 if self.stop_eval: break
-                features, _ = self.audio_featurizer(audio, input_lens_ratio)
-                if self.configs.use_model == 'EcapaTdnn':
-                    output = eval_model([features, input_lens_ratio])
-                else:
-                    output = eval_model(features)
+                output = eval_model(features)
                 los = self.loss(output, label)
                 # 计算准确率
                 label = paddle.reshape(label, shape=(-1, 1))
                 acc = accuracy(input=paddle.nn.functional.softmax(output), label=label)
                 accuracies.append(float(acc))
                 losses.append(float(los))
                 # 模型预测标签
```

## ppacls/data_utils/collate_fn.py

```diff
@@ -1,24 +1,23 @@
-import numpy as np
+import paddle
 
 
 # 对一个batch的数据处理
 def collate_fn(batch):
     # 找出音频长度最长的
-    batch = sorted(batch, key=lambda sample: sample[0].shape[0], reverse=True)
-    max_audio_length = batch[0][0].shape[0]
-    batch_size = len(batch)
+    batch_sorted = sorted(batch, key=lambda sample: sample[0].shape[0], reverse=True)
+    freq_size = batch_sorted[0][0].shape[1]
+    max_freq_length = batch_sorted[0][0].shape[0]
+    batch_size = len(batch_sorted)
     # 以最大的长度创建0张量
-    inputs = np.zeros((batch_size, max_audio_length), dtype='float32')
-    input_lens_ratio = []
-    labels = []
+    features = paddle.zeros((batch_size, max_freq_length, freq_size), dtype=paddle.float32)
+    input_lens, labels = [], []
     for x in range(batch_size):
-        sample = batch[x]
-        tensor = sample[0]
-        labels.append(sample[1])
+        tensor, label = batch[x]
         seq_length = tensor.shape[0]
         # 将数据插入都0张量中，实现了padding
-        inputs[x, :seq_length] = tensor[:]
-        input_lens_ratio.append(seq_length/max_audio_length)
-    input_lens_ratio = np.array(input_lens_ratio, dtype='float32')
-    labels = np.array(labels, dtype='int64')
-    return inputs, labels, input_lens_ratio
+        features[x, :seq_length, :] = tensor[:, :]
+        labels.append(label)
+        input_lens.append(seq_length)
+    labels = paddle.to_tensor(labels, dtype=paddle.int64)
+    input_lens = paddle.to_tensor(input_lens, dtype=paddle.int64)
+    return features, labels, input_lens
```

## ppacls/data_utils/featurizer.py

```diff
@@ -26,39 +26,42 @@
         elif feature_method == 'MFCC':
             self.feat_fun = MFCC(**method_args)
         elif feature_method == 'Fbank':
             self.feat_fun = KaldiFbank(**method_args)
         else:
             raise Exception(f'预处理方法 {self._feature_method} 不存在!')
 
-    def forward(self, waveforms, input_lens_ratio):
+    def forward(self, waveforms, input_lens_ratio=None):
         """从AudioSegment中提取音频特征
 
         :param waveforms: Audio segment to extract features from.
         :type waveforms: AudioSegment
         :param input_lens_ratio: input length ratio
         :type input_lens_ratio: tensor
         :return: Spectrogram audio feature in 2darray.
         :rtype: ndarray
         """
+        if len(waveforms.shape) == 1:
+            waveforms = waveforms.unsqueeze(0)
         feature = self.feat_fun(waveforms)
         feature = feature.transpose([0, 2, 1])
         # 归一化
         feature = feature - feature.mean(1, keepdim=True)
-        # 对掩码比例进行扩展
-        input_lens = (input_lens_ratio * feature.shape[1]).astype(paddle.int32)
-        mask_lens = input_lens.unsqueeze(1)
-        # 生成掩码张量
-        idxs = paddle.arange(feature.shape[1])
-        idxs = idxs.tile([feature.shape[0], 1])
-        mask = idxs < mask_lens
-        mask = mask.unsqueeze(-1)
-        # 对特征进行掩码操作
-        feature_masked = paddle.where(mask, feature, paddle.zeros_like(feature))
-        return feature_masked, input_lens
+        if input_lens_ratio is not None:
+            # 对掩码比例进行扩展
+            input_lens = (input_lens_ratio * feature.shape[1]).astype(paddle.int32)
+            mask_lens = input_lens.unsqueeze(1)
+            # 生成掩码张量
+            idxs = paddle.arange(feature.shape[1])
+            idxs = idxs.tile([feature.shape[0], 1])
+            mask = idxs < mask_lens
+            mask = mask.unsqueeze(-1)
+            # 对特征进行掩码操作
+            feature = paddle.where(mask, feature, paddle.zeros_like(feature))
+        return feature
 
     @property
     def feature_dim(self):
         """返回特征大小
 
         :return: 特征大小
         :rtype: int
```

## ppacls/data_utils/reader.py

```diff
@@ -1,86 +1,114 @@
 import os
+import paddle
 import random
 
 import numpy as np
 from paddle.io import Dataset
 
 from ppacls.data_utils.audio import AudioSegment
+from ppacls.data_utils.featurizer import AudioFeaturizer
 from ppacls.utils.logger import setup_logger
 
 logger = setup_logger(__name__)
 
 
 # 音频数据加载器
-class CustomDataset(Dataset):
+class PPAClsDataset(Dataset):
     def __init__(self,
                  data_list_path,
+                 audio_featurizer: AudioFeaturizer,
                  do_vad=True,
                  max_duration=3,
                  min_duration=0.5,
                  mode='train',
                  sample_rate=16000,
                  aug_conf={},
                  use_dB_normalization=True,
                  target_dB=-20):
         """音频数据加载器
 
         Args:
             data_list_path: 包含音频路径和标签的数据列表文件的路径
+            audio_featurizer: 声纹特征提取器
             do_vad: 是否对音频进行语音活动检测（VAD）来裁剪静音部分
             max_duration: 最长的音频长度，大于这个长度会裁剪掉
             min_duration: 过滤最短的音频长度
             aug_conf: 用于指定音频增强的配置
             mode: 数据集模式。在训练模式下，数据集可能会进行一些数据增强的预处理
             sample_rate: 采样率
             use_dB_normalization: 是否对音频进行音量归一化
             target_dB: 音量归一化的大小
         """
-        super(CustomDataset, self).__init__()
+        super(PPAClsDataset, self).__init__()
+        assert mode in ['train', 'eval', 'create_data', 'extract_feature']
         self.do_vad = do_vad
         self.max_duration = max_duration
         self.min_duration = min_duration
         self.mode = mode
         self._target_sample_rate = sample_rate
         self._use_dB_normalization = use_dB_normalization
         self._target_dB = target_dB
         self.aug_conf = aug_conf
         self.noises_path = None
+        # 获取特征器
+        self.audio_featurizer = audio_featurizer
+        # 获取特征裁剪的大小
+        self.max_feature_len = self.get_crop_feature_len()
         # 获取数据列表
         with open(data_list_path, 'r') as f:
             self.lines = f.readlines()
 
     def __getitem__(self, idx):
-        # 分割音频路径和标签
-        audio_path, label = self.lines[idx].strip().split('\t')
-        # 读取音频
-        audio_segment = AudioSegment.from_file(audio_path)
-        # 裁剪静音
-        if self.do_vad:
-            audio_segment.vad()
-        # 数据太短不利于训练
-        if self.mode == 'train':
-            if audio_segment.duration < self.min_duration:
-                return self.__getitem__(idx + 1 if idx < len(self.lines) - 1 else 0)
-        # 重采样
-        if audio_segment.sample_rate != self._target_sample_rate:
-            audio_segment.resample(self._target_sample_rate)
-        # 音频增强
-        if self.mode == 'train':
-            audio_segment = self.augment_audio(audio_segment, **self.aug_conf)
-        # decibel normalization
-        if self._use_dB_normalization:
-            audio_segment.normalize(target_db=self._target_dB)
-        # 裁剪需要的数据
-        audio_segment.crop(duration=self.max_duration, mode=self.mode)
-        return np.array(audio_segment.samples, dtype=np.float32), np.array(int(label), dtype=np.int64)
+        # 分割数据文件路径和标签
+        data_path, label = self.lines[idx].replace('\n', '').split('\t')
+        label = paddle.to_tensor(int(label), dtype=paddle.int64)
+        # 如果后缀名为.npy的文件，那么直接读取
+        if data_path.endswith('.npy'):
+            feature = np.load(data_path)
+            if feature.shape[0] > self.max_feature_len:
+                crop_start = random.randint(0, feature.shape[0] - self.max_feature_len) if self.mode == 'eval' else 0
+                feature = feature[crop_start:crop_start + self.max_feature_len, :]
+            feature = paddle.to_tensor(feature, dtype=paddle.float32)
+        else:
+            # 读取音频
+            audio_segment = AudioSegment.from_file(data_path)
+            # 裁剪静音
+            if self.do_vad:
+                audio_segment.vad()
+            # 数据太短不利于训练
+            if self.mode == 'train':
+                if audio_segment.duration < self.min_duration:
+                    return self.__getitem__(idx + 1 if idx < len(self.lines) - 1 else 0)
+            # 重采样
+            if audio_segment.sample_rate != self._target_sample_rate:
+                audio_segment.resample(self._target_sample_rate)
+            # 音频增强
+            if self.mode == 'train':
+                audio_segment = self.augment_audio(audio_segment, **self.aug_conf)
+            # decibel normalization
+            if self._use_dB_normalization:
+                audio_segment.normalize(target_db=self._target_dB)
+            # 裁剪需要的数据
+            if self.mode != 'extract_feature' and audio_segment.duration > self.max_duration:
+                audio_segment.crop(duration=self.max_duration, mode=self.mode)
+            samples = paddle.to_tensor(audio_segment.samples, dtype=paddle.float32)
+            feature = self.audio_featurizer(samples)
+            feature = feature.squeeze(0)
+        return feature, label
 
     def __len__(self):
         return len(self.lines)
 
+    def get_crop_feature_len(self):
+        samples = paddle.randn((1, self.max_duration * self._target_sample_rate))
+        feature = self.audio_featurizer(samples).squeeze(0)
+        freq_len = feature.shape[0]
+        return freq_len
+
     # 音频增强
     def augment_audio(self,
                       audio_segment,
                       speed_perturb=False,
                       volume_perturb=False,
                       volume_aug_prob=0.2,
                       noise_dir=None,
```

## ppacls/models/ecapa_tdnn.py

```diff
@@ -241,29 +241,25 @@
                              out_channels=self.embd_dim,
                              kernel_size=1)
         else:
             raise Exception(f'没有{pooling_type}池化层！')
 
         self.output = nn.Linear(self.embd_dim, num_class)
 
-    def forward(self, x):
+    def forward(self, x, lengths=None):
         """
         Compute embeddings.
 
         Args:
             x (paddle.Tensor): Input data with shape (N, time, freq).
             lengths (paddle.Tensor, optional): Length proportions of batch length with shape (N). Defaults to None.
 
         Returns:
             paddle.Tensor: Output embeddings with shape (N, self.emb_size, 1)
         """
-        if isinstance(x, list):
-            x, lengths = x
-        else:
-            lengths = None
         x = x.transpose([0, 2, 1])
         xl = []
         for layer in self.blocks:
             try:
                 x = layer(x, lengths=lengths)
             except TypeError:
                 x = layer(x)
```

## Comparing `ppacls-0.4.3.dist-info/LICENSE` & `ppacls-0.4.4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `ppacls-0.4.3.dist-info/METADATA` & `ppacls-0.4.4.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: ppacls
-Version: 0.4.3
+Version: 0.4.4
 Summary: Audio Classification toolkit on PaddlePaddle
 Home-page: https://github.com/yeyupiaoling/AudioClassification_PaddlePaddle
 Download-URL: https://github.com/yeyupiaoling/AudioClassification_PaddlePaddle.git
 Author: yeyupiaoling
 License: Apache License 2.0
 Keywords: audio,paddle
 Classifier: Intended Audience :: Developers
@@ -134,15 +134,15 @@
 ```shell
 dataset/UrbanSound8K/audio/fold2/104817-4-0-2.wav	4
 dataset/UrbanSound8K/audio/fold9/105029-7-2-5.wav	7
 dataset/UrbanSound8K/audio/fold3/107228-5-0-0.wav	5
 dataset/UrbanSound8K/audio/fold4/109711-3-2-4.wav	3
 ```
 
-# 修改预处理方法
+# 修改预处理方法（可选）
 
 配置文件中默认使用的是MelSpectrogram预处理方法，如果要使用其他预处理方法，可以修改配置文件中的安装下面方式修改，具体的值可以根据自己情况修改。如果不清楚如何设置参数，可以直接删除该部分，直接使用默认值。
 
 ```yaml
 preprocess_conf:
   # 音频预处理方法，支持：MelSpectrogram、Spectrogram、MFCC、Fbank
   feature_method: 'MelSpectrogram'
@@ -153,14 +153,27 @@
     hop_length: 320
     win_length: 1024
     f_min: 50.0
     f_max: 14000.0
     n_mels: 64
 ```
 
+# 提取特征（可选）
+
+在训练过程中，首先是要读取音频数据，然后提取特征，最后再进行训练。其中读取音频数据、提取特征也是比较消耗时间的，所以我们可以选择提前提取好取特征，训练模型的是就可以直接加载提取好的特征，这样训练速度会更快。这个提取特征是可选择，如果没有提取好的特征，训练模型的时候就会从读取音频数据，然后提取特征开始。提取特征步骤如下：
+
+1. 执行`extract_features.py`，提取特征，特征会保存在`dataset/features`目录下，并生成新的数据列表`train_list_features.txt`和`test_list_features.txt`。
+
+```shell
+python extract_features.py --configs=configs/cam++.yml --save_dir=dataset/features
+```
+
+2. 修改配置文件，将`dataset_conf.train_list`和`dataset_conf.test_list`修改为`train_list_features.txt`和`test_list_features.txt`。
+
+
 ## 训练
 
 接着就可以开始训练模型了，创建 `train.py`。配置文件里面的参数一般不需要修改，但是这几个是需要根据自己实际的数据集进行调整的，首先最重要的就是分类大小`dataset_conf.num_class`，这个每个数据集的分类大小可能不一样，根据自己的实际情况设定。然后是`dataset_conf.batch_size`，如果是显存不够的话，可以减小这个参数。
 
 ```shell
 # 单卡训练
 CUDA_VISIBLE_DEVICES=0 python train.py
```

## Comparing `ppacls-0.4.3.dist-info/RECORD` & `ppacls-0.4.4.dist-info/RECORD`

 * *Files 17% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-ppacls/__init__.py,sha256=iUVruvBi_BFZRV6LsDpD2SIswAjsmjVViarSBK9R6C0,196
-ppacls/predict.py,sha256=_GWg2Q2z2vzyDgNhbJlEq4QB1ykJyPFF3yoJUdA9TLU,9423
-ppacls/trainer.py,sha256=MsoMhgk2qMqLjFY8_9FYgdE520jVGqqz1nsVt8uAXr0,27319
+ppacls/__init__.py,sha256=hJm_b0gqR9Bo1fgpUjzLAoiKn6FBZwVQ10pBedhQ31E,196
+ppacls/predict.py,sha256=Y-XrwV4YBAhC_mng4qRvJ34VeUqgwezk4W7XgxlS76c,8988
+ppacls/trainer.py,sha256=YAYq2rMOkRMBnTFCAparBTvg41_eFFeA7bIKeAetMF4,28974
 ppacls/data_utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ppacls/data_utils/audio.py,sha256=OZ1NTIy99fb2LBvelNn2ftDSzDYGNyzufqvDcV5LtE0,22219
-ppacls/data_utils/collate_fn.py,sha256=tb5yu7VH69x1nGKxJUBoZ5UNsVgYxZ_zbth2YN52zPw,909
-ppacls/data_utils/featurizer.py,sha256=9j7nEQbe1f5udaxZwFIG6D_erTW3gMKuIZB2cd3-hMI,3771
-ppacls/data_utils/reader.py,sha256=7S6ufieGeLkk7SoHcrpeEGHpGTC3BN7QhQyF6KulVtk,5507
+ppacls/data_utils/collate_fn.py,sha256=uzm-U3avFXzjJXbM6u5CfUJUr4WlIYcaz7WDmgetRys,947
+ppacls/data_utils/featurizer.py,sha256=wWgZoR0ZdTZ0Ux0byI4qT2Go86njSxFskQFz8xtipf0,3919
+ppacls/data_utils/reader.py,sha256=AnZcuk4ImESpBRGg2n_yqQqEMZ4aUFXt4l4ijyhlk18,7042
 ppacls/data_utils/spec_aug.py,sha256=Qw32xZTw1f8Fk3Kw9aQt_5IKiH8k1giXbCX3XUzU1xw,1581
 ppacls/data_utils/utils.py,sha256=_pBlkOSs0yrSFzeGfh_TcB62qhRwuae5erknOiCxh7o,4698
 ppacls/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ppacls/models/campplus.py,sha256=5D8WL-Xd3N6kWLdC1A0DMsIq0sdCpDYMYkrI62yBc18,12884
-ppacls/models/ecapa_tdnn.py,sha256=MOMl3y_iVFAUrrXjgEw5xSHqrw5qJllhSrHtkdjFGQU,11182
+ppacls/models/ecapa_tdnn.py,sha256=NS2nbMQI04QX8EXNeXOZIC1TMWFxnXcA8DtJyAWpT5w,11092
 ppacls/models/eres2net.py,sha256=ygD1lpRl5fxH3D1aVcg2b1pDq-hM0NgJuvwZ7z8RPcQ,10451
 ppacls/models/panns.py,sha256=4L2JQgaSQyIvWNCmr7zKmU0oiHOwN3nGB1FD5hQbSUM,9863
 ppacls/models/pooling.py,sha256=K-GszyrPIZd_8pACrsNYXQizQDnuWrQWQNBTG6ZWVuY,5277
 ppacls/models/res2net.py,sha256=ngLXP9jnyg846rGp2vWobIq4fRBNtsQr8nUpOQE44Vc,6941
 ppacls/models/resnet_se.py,sha256=77KZuOzmN0h1U67Ezb_pt7VWDM94yDml6z2EdBuhOU0,5760
 ppacls/models/tdnn.py,sha256=VkAYLXZ20JHG4NUdHMYz1T0CetL8d7xOefM3rNPGVIc,3557
 ppacls/models/utils.py,sha256=WFaGb66sSLalS-2yr9VIOnICrLjR8rGmiggGaWnZV_Y,5049
 ppacls/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ppacls/utils/logger.py,sha256=-ssorx8FlHA_wrd2Eq6f4HkOqaOG2YseBGvYAo8NXN8,2839
 ppacls/utils/record.py,sha256=2i4kz5kPDa9KkbAK_Q34sVIXOkD9TroPROIe5QdzqWg,1067
 ppacls/utils/scheduler.py,sha256=IZ1kU6S86hfnuZLfkepflStogDyYvRPEDMP4P_mwGvs,3399
 ppacls/utils/utils.py,sha256=7WKE_Mf03J6Zt3F45A-jigDU13zx-1uQ5MMhS8C3VrU,4301
-ppacls-0.4.3.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
-ppacls-0.4.3.dist-info/METADATA,sha256=QKQjbW75Gjq0eMwVDbNsDyDgHrYvpY1m2z3TSiK1xyU,22776
-ppacls-0.4.3.dist-info/WHEEL,sha256=yQN5g4mg4AybRjkgi-9yy4iQEFibGQmlz78Pik5Or-A,92
-ppacls-0.4.3.dist-info/top_level.txt,sha256=RkvwIMbjgjfhvlagK7GKtMw9ZSfGRMbY4vk2nbLpvrY,7
-ppacls-0.4.3.dist-info/RECORD,,
+ppacls-0.4.4.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
+ppacls-0.4.4.dist-info/METADATA,sha256=ynoPij85PsVddUs0oYZ5mwE55aC_6fImwEM_fmBm6Xg,23734
+ppacls-0.4.4.dist-info/WHEEL,sha256=yQN5g4mg4AybRjkgi-9yy4iQEFibGQmlz78Pik5Or-A,92
+ppacls-0.4.4.dist-info/top_level.txt,sha256=RkvwIMbjgjfhvlagK7GKtMw9ZSfGRMbY4vk2nbLpvrY,7
+ppacls-0.4.4.dist-info/RECORD,,
```

